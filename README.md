# TextGen-AI-Transformer-Trainer

A lightweight Python framework for fine-tuning transformer models (GPT-2 / T5) on your own custom text datasets.  
Supports both **text generation** and **interactive chatbot** mode using Hugging Face Transformers.  
Works seamlessly on **Google Colab** and in **local environments**.

---

## Features

- âœ… Fine-tune **GPT-2** or **T5** on `.txt`, `.csv`, or `.json` files.
- âœ… Automatically saves models by dataset + model name.
- âœ… Built-in **inference** and **chat** modes.
- âœ… Supports Hugging Face Datasets and custom files.
- âœ… Runs on **Google Colab**, local machines, or remote servers.
- âœ… Clean modular code: `preprocess.py`,`train.py`,`inference.py`.

---

## ğŸ“ Project Structure

```
TextGen-AI-Transformer-Trainer/
â”œâ”€â”€ datasets/                 # Sample & custom dataset files
â”œâ”€â”€ docs/                     # Documentation (setup guide, etc.)
â”œâ”€â”€ logs/                     # Training logs directory
â”œâ”€â”€ models/                   # Trained model output directory
â”œâ”€â”€ notebooks/                # Jupyter / Colab notebooks
â”‚   â””â”€â”€ TextGen_Colab.ipynb   # Colab-friendly training/inference notebook
â”œâ”€â”€ src/                      # Main training and inference code
â”‚   â”œâ”€â”€ train.py              # Training script
â”‚   â”œâ”€â”€ inference.py          # Inference & chatbot script
â”‚   â””â”€â”€ preprocess.py         # Data loading and preprocessing logic
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # Project overview and instructions
â””â”€â”€ .gitignore                # Git ignore rules
```

---

## ğŸ”§ Setup Options

### â–¶ï¸ Option 1: Google Colab (Recommended).

No setup needed â€” everything runs in the cloud.

1. **Fork** this repository to your own GitHub.
2. Open the Colab Notebook (notebooks/TextGen_Colab.ipynb).
```
https://colab.research.google.com/github/YOUR_USERNAME/TextGen-AI-Transformer-Trainer/blob/main/notebooks/TextGen_Colab.ipynb
```
3. Follow the instructions to:
   - Mount Google Drive
   - Clone your fork
   - Train a model using your dataset
   - Run inference or launch chat mode

---

### ğŸ’» Option 2: Run Locally

#### Step 1: Clone the repository
```
git clone https://github.com/NimeshRawanage/TextGen-AI-Transformer-Trainer.git
cd TextGen-AI-Transformer-Trainer
```
Step 2: Install dependencies
```
pip install -r requirements.txt
```
Step 3: Train the model
```
python src/train.py \
  --model gpt2 \
  --dataset_path datasets/sample_data.txt \
  --epochs 3 \
  --batch_size 4 \
  --output_dir models/
```
Step 4: Run inference

```
python src/inference.py \
  --model_dir models/gpt2_sample_data \
  --prompt "Once upon a time" \
  --max_length 50
```

Step 5: Launch chatbot mode

```
python src/inference.py \
  --model_dir models/gpt2_sample_data \
  --mode chat
```

## ğŸ“„ Supported Dataset File Formats

.txt â†’ Each line as a training sample

.csv or .json â†’ First column as text input

---

## ğŸ“š Documentation

A full setup guide is available in docs/setup_guide.md

---

## ğŸ“Œ License

This project is licensed under the MIT License.

---
â­ If you find this helpful, please star the repository and share it with others!

---

**Author**: Nimesh Rawanage  
AI Engineer & Backend Developer  
**GitHub**: [github.com/NimeshRawanage](https://github.com/NimeshRawanage)  
**LinkedIn**: [linkedin.com/in/nimeshrawanage](https://linkedin.com/in/nimeshrawanage)

